{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPoUCQWgMmlj/5XyPvikstv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanhith25/Credit-risk-modelling-/blob/main/Credit_risk_modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "g2kir-vFJA_a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import chi2_contingency, f_oneway\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    precision_recall_fscore_support\n",
        ")"
      ],
      "metadata": {
        "id": "hz0fgtQKJIHE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "hRfZ4obMJKee"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_excel(\"case_study1.xlsx\")\n",
        "df2 = pd.read_excel(\"case_study2.xlsx\")"
      ],
      "metadata": {
        "id": "vYO5gJSCJNwl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df1.copy()\n",
        "df2 = df2.copy()"
      ],
      "metadata": {
        "id": "PfBe-oVMMzLC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In df1, remove rows where Age_Oldest_TL is -99999\n",
        "if \"Age_Oldest_TL\" in df1.columns:\n",
        "    df1 = df1.loc[df1[\"Age_Oldest_TL\"] != -99999]\n",
        "\n",
        "# In df2, drop columns with too many -99999, then rows with remaining -99999\n",
        "columns_to_drop = []\n",
        "for col in df2.columns:\n",
        "    if (df2[col] == -99999).sum() > 10000:\n",
        "        columns_to_drop.append(col)\n",
        "\n",
        "df2 = df2.drop(columns_to_drop, axis=1)\n",
        "\n",
        "for col in df2.columns:\n",
        "    df2 = df2.loc[df2[col] != -99999]"
      ],
      "metadata": {
        "id": "cvhHV7kbM7NU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. MERGE DATASETS ON PROSPECTID\n",
        "df = pd.merge(df1, df2, on=\"PROSPECTID\", how=\"inner\")\n",
        "print(\"Shape after merge:\", df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGuJ8JleM9wn",
        "outputId": "71f95ddc-457d-4cb5-f571-8c5ede826a87"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after merge: (42064, 79)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " CATEGORICAL FEATURE SELECTION (CHI-SQUARE TEST)"
      ],
      "metadata": {
        "id": "j4sfPdR9NO-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_cols = [c for c in df.columns if df[c].dtype == \"object\"]\n",
        "print(\"Categorical columns:\", categorical_cols)\n",
        "\n",
        "cat_candidates = [\"MARITALSTATUS\", \"EDUCATION\", \"GENDER\", \"last_prod_enq2\", \"first_prod_enq2\"]\n",
        "cat_candidates = [c for c in cat_candidates if c in df.columns]\n",
        "\n",
        "print(\"\\nChi-square p-values vs Approved_Flag:\")\n",
        "useful_cats = []\n",
        "for col in cat_candidates:\n",
        "    contingency = pd.crosstab(df[col], df[\"Approved_Flag\"])\n",
        "    chi2, pval, _, _ = chi2_contingency(contingency)\n",
        "    print(f\"{col}: p-value = {pval:.4f}\")\n",
        "    if pval <= 0.05:\n",
        "        useful_cats.append(col)\n",
        "\n",
        "print(\"Selected categorical features:\", useful_cats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggHP1FkSNH60",
        "outputId": "891b71a4-bee9-4ab9-cb73-344dd976cfe1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorical columns: ['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2', 'first_prod_enq2', 'Approved_Flag']\n",
            "\n",
            "Chi-square p-values vs Approved_Flag:\n",
            "MARITALSTATUS: p-value = 0.0000\n",
            "EDUCATION: p-value = 0.0000\n",
            "GENDER: p-value = 0.0000\n",
            "last_prod_enq2: p-value = 0.0000\n",
            "first_prod_enq2: p-value = 0.0000\n",
            "Selected categorical features: ['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2', 'first_prod_enq2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_cols = [\n",
        "    c for c in df.columns\n",
        "    if (df[c].dtype != \"object\") and (c not in [\"PROSPECTID\"]) and (c != \"Approved_Flag\")\n",
        "]\n",
        "\n",
        "vif_df = df[numeric_cols].copy()"
      ],
      "metadata": {
        "id": "aRfceSR3NTC5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iteratively drop columns with VIF > 6\n",
        "while True:\n",
        "    vif_values = pd.Series(\n",
        "        [variance_inflation_factor(vif_df.values, i) for i in range(vif_df.shape[1])],\n",
        "        index=vif_df.columns,\n",
        "        name=\"VIF\"\n",
        "    )\n",
        "    max_vif = vif_values.max()\n",
        "    if max_vif > 6:\n",
        "        drop_col = vif_values.idxmax()\n",
        "        print(f\"Dropping {drop_col} due to high VIF = {max_vif:.2f}\")\n",
        "        vif_df = vif_df.drop(columns=[drop_col])\n",
        "    else:\n",
        "        break\n",
        "\n",
        "selected_numeric_vif = list(vif_df.columns)\n",
        "print(\"\\nNumeric features after VIF filtering:\", len(selected_numeric_vif))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zexOqnhNYPZ",
        "outputId": "a678663a-429d-4f37-b125-1faa45aca05f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropping Total_TL due to high VIF = inf\n",
            "Dropping Tot_Closed_TL due to high VIF = inf\n",
            "Dropping pct_active_tl due to high VIF = inf\n",
            "Dropping Auto_TL due to high VIF = inf\n",
            "Dropping num_deliq_6mts due to high VIF = inf\n",
            "Dropping pct_of_active_TLs_ever due to high VIF = 2688.95\n",
            "Dropping Secured_TL due to high VIF = 91.07\n",
            "Dropping enq_L12m due to high VIF = 36.97\n",
            "Dropping Credit_Score due to high VIF = 33.38\n",
            "Dropping num_std_12mts due to high VIF = 26.13\n",
            "Dropping pct_PL_enq_L6m_of_L12m due to high VIF = 24.11\n",
            "Dropping Total_TL_opened_L12M due to high VIF = 22.14\n",
            "Dropping Unsecured_TL due to high VIF = 19.94\n",
            "Dropping pct_CC_enq_L6m_of_L12m due to high VIF = 19.16\n",
            "Dropping enq_L6m due to high VIF = 16.72\n",
            "Dropping num_times_30p_dpd due to high VIF = 13.68\n",
            "Dropping AGE due to high VIF = 12.92\n",
            "Dropping PL_enq_L12m due to high VIF = 12.43\n",
            "Dropping Tot_Active_TL due to high VIF = 12.32\n",
            "Dropping num_dbt_12mts due to high VIF = 9.48\n",
            "Dropping Tot_TL_closed_L12M due to high VIF = 9.23\n",
            "Dropping CC_enq_L12m due to high VIF = 9.08\n",
            "Dropping tot_enq due to high VIF = 8.98\n",
            "Dropping num_deliq_12mts due to high VIF = 8.21\n",
            "Dropping num_lss_12mts due to high VIF = 8.12\n",
            "Dropping pct_tl_open_L6M due to high VIF = 7.23\n",
            "Dropping pct_closed_tl due to high VIF = 6.78\n",
            "\n",
            "Numeric features after VIF filtering: 45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ANOVA across Approved_Flag groups\n",
        "columns_to_keep_numerical = []\n",
        "target = \"Approved_Flag\"\n",
        "\n",
        "for col in selected_numeric_vif:\n",
        "    # building groups per class\n",
        "    groups = []\n",
        "    for cls in df[target].unique():\n",
        "        groups.append(df.loc[df[target] == cls, col].values)\n",
        "\n",
        "    # min 2 values each\n",
        "    if all(len(g) > 1 for g in groups):\n",
        "        f_stat, p_val = f_oneway(*groups)\n",
        "        if p_val <= 0.05:\n",
        "            columns_to_keep_numerical.append(col)\n",
        "\n",
        "print(\"\\nNumeric features after ANOVA:\", len(columns_to_keep_numerical))\n",
        "print(columns_to_keep_numerical)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7ND0lh6NhZX",
        "outputId": "c7ab8a6f-bcdb-49c7-af92-33204fbd3023"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Numeric features after ANOVA: 43\n",
            "['Total_TL_opened_L6M', 'Tot_TL_closed_L6M', 'pct_tl_closed_L6M', 'pct_tl_open_L12M', 'pct_tl_closed_L12M', 'Tot_Missed_Pmnt', 'CC_TL', 'Consumer_TL', 'Gold_TL', 'Home_TL', 'PL_TL', 'Other_TL', 'Age_Oldest_TL', 'Age_Newest_TL', 'time_since_recent_payment', 'num_times_delinquent', 'max_recent_level_of_deliq', 'num_deliq_6_12mts', 'num_times_60p_dpd', 'num_std', 'num_std_6mts', 'num_sub', 'num_sub_6mts', 'num_sub_12mts', 'num_dbt', 'num_dbt_6mts', 'num_lss', 'recent_level_of_deliq', 'CC_enq', 'CC_enq_L6m', 'PL_enq', 'PL_enq_L6m', 'time_since_recent_enq', 'enq_L3m', 'NETMONTHLYINCOME', 'Time_With_Curr_Empr', 'pct_opened_TLs_L6m_of_L12m', 'CC_Flag', 'PL_Flag', 'pct_PL_enq_L6m_of_ever', 'pct_CC_enq_L6m_of_ever', 'HL_Flag', 'GL_Flag']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. FINAL FEATURE SET\n",
        "features = columns_to_keep_numerical + useful_cats\n",
        "features = list(dict.fromkeys(features))  # removing duplicates\n",
        "\n",
        "df = df[features + [target]].copy()\n",
        "print(\"\\nFinal feature set:\", len(features))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLpIP5XPNwY5",
        "outputId": "0336949e-5140-4057-b391-0ddc6ea00fa2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final feature set: 48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. ENCODING CATEGORICAL FEATURES\n",
        "# Clean EDUCATION into ordinal values if present\n",
        "if \"EDUCATION\" in df.columns:\n",
        "    df.loc[df[\"EDUCATION\"] == \"SSC\", \"EDUCATION\"] = 1\n",
        "    df.loc[df[\"EDUCATION\"] == \"12TH\", \"EDUCATION\"] = 2\n",
        "    df.loc[df[\"EDUCATION\"] == \"GRADUATE\", \"EDUCATION\"] = 3\n",
        "    df.loc[df[\"EDUCATION\"] == \"UNDER GRADUATE\", \"EDUCATION\"] = 3\n",
        "    df.loc[df[\"EDUCATION\"] == \"POST-GRADUATE\", \"EDUCATION\"] = 4\n",
        "    df.loc[df[\"EDUCATION\"] == \"OTHERS\", \"EDUCATION\"] = 1\n",
        "    df.loc[df[\"EDUCATION\"] == \"PROFESSIONAL\", \"EDUCATION\"] = 3\n",
        "    df[\"EDUCATION\"] = df[\"EDUCATION\"].astype(int)"
      ],
      "metadata": {
        "id": "vC9shEp1OAet"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Onehot encoding remaining categoricals except EDUCATION if you treat it as numeric\n",
        "one_hot_cols = [c for c in useful_cats if c != \"EDUCATION\"]\n",
        "\n",
        "df_encoded = pd.get_dummies(df, columns=one_hot_cols)\n",
        "\n",
        "print(\"\\nEncoded data shape:\", df_encoded.shape)\n",
        "print(df_encoded.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFZmVzZuOF2G",
        "outputId": "36c5ac14-bc15-4740-c846-6b74b8bc4eab"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Encoded data shape: (42064, 61)\n",
            "   Total_TL_opened_L6M  Tot_TL_closed_L6M  pct_tl_closed_L6M  \\\n",
            "0                    0                  0                0.0   \n",
            "1                    0                  0                0.0   \n",
            "2                    1                  0                0.0   \n",
            "3                    0                  0                0.0   \n",
            "4                    0                  0                0.0   \n",
            "\n",
            "   pct_tl_open_L12M  pct_tl_closed_L12M  Tot_Missed_Pmnt  CC_TL  Consumer_TL  \\\n",
            "0              0.00               0.000                0      0            0   \n",
            "1              1.00               0.000                0      0            1   \n",
            "2              0.25               0.000                1      0            6   \n",
            "3              0.00               0.000                0      0            0   \n",
            "4              0.00               0.167                0      0            0   \n",
            "\n",
            "   Gold_TL  Home_TL  ...  last_prod_enq2_ConsumerLoan  last_prod_enq2_HL  \\\n",
            "0        1        0  ...                        False              False   \n",
            "1        0        0  ...                         True              False   \n",
            "2        1        0  ...                         True              False   \n",
            "3        0        0  ...                        False              False   \n",
            "4        2        0  ...                         True              False   \n",
            "\n",
            "   last_prod_enq2_PL  last_prod_enq2_others  first_prod_enq2_AL  \\\n",
            "0               True                  False               False   \n",
            "1              False                  False               False   \n",
            "2              False                  False               False   \n",
            "3              False                  False                True   \n",
            "4              False                  False               False   \n",
            "\n",
            "   first_prod_enq2_CC  first_prod_enq2_ConsumerLoan  first_prod_enq2_HL  \\\n",
            "0               False                         False               False   \n",
            "1               False                          True               False   \n",
            "2               False                         False               False   \n",
            "3               False                         False               False   \n",
            "4               False                         False               False   \n",
            "\n",
            "   first_prod_enq2_PL  first_prod_enq2_others  \n",
            "0                True                   False  \n",
            "1               False                   False  \n",
            "2               False                    True  \n",
            "3               False                   False  \n",
            "4                True                   False  \n",
            "\n",
            "[5 rows x 61 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df_encoded[target]\n",
        "X = df_encoded.drop(columns=[target])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"\\nTrain shape:\", X_train.shape, \" Test shape:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Avuts7f9OSw1",
        "outputId": "c6bdb186-6aa1-4657-b05e-89e6ee71d373"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train shape: (33651, 60)  Test shape: (8413, 60)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Random forest**"
      ],
      "metadata": {
        "id": "WyXhW915Obhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred_rf = rf_clf.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(classification_report(y_test, y_pred_rf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jK19Xq3bOWYe",
        "outputId": "bdde78ac-d925-4a2f-af1d-bb8c3cd9b173"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7671460834422917\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          P1       0.83      0.71      0.77       982\n",
            "          P2       0.80      0.93      0.86      5090\n",
            "          P3       0.43      0.21      0.28      1288\n",
            "          P4       0.74      0.71      0.72      1053\n",
            "\n",
            "    accuracy                           0.77      8413\n",
            "   macro avg       0.70      0.64      0.66      8413\n",
            "weighted avg       0.74      0.77      0.74      8413\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Decision tree**"
      ],
      "metadata": {
        "id": "VK5WFq5eOhs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt_clf = DecisionTreeClassifier(max_depth=20, min_samples_split=10, random_state=42)\n",
        "dt_clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred_dt = dt_clf.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
        "print(classification_report(y_test, y_pred_dt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gA7xOTuDOfWe",
        "outputId": "15196e15-7d95-4986-9a65-cbec5592c6d5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7080708427433734\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          P1       0.70      0.71      0.71       982\n",
            "          P2       0.80      0.83      0.81      5090\n",
            "          P3       0.32      0.30      0.31      1288\n",
            "          P4       0.69      0.63      0.66      1053\n",
            "\n",
            "    accuracy                           0.71      8413\n",
            "   macro avg       0.63      0.62      0.62      8413\n",
            "weighted avg       0.70      0.71      0.70      8413\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **XGB**"
      ],
      "metadata": {
        "id": "BNCEqrOuOuog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "X_train_xgb, X_test_xgb, y_train_xgb, y_test_xgb = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    objective=\"multi:softmax\",\n",
        "    num_class=len(label_encoder.classes_),\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb_clf.fit(X_train_xgb, y_train_xgb)\n",
        "y_pred_xgb = xgb_clf.predict(X_test_xgb)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test_xgb, y_pred_xgb))\n",
        "print(classification_report(y_test_xgb, y_pred_xgb, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjSPEyz2Okqg",
        "outputId": "970772d8-18c7-4554-99b1-0585c7102ad5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7727326756210626\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          P1       0.81      0.76      0.79       982\n",
            "          P2       0.82      0.91      0.86      5090\n",
            "          P3       0.42      0.28      0.34      1288\n",
            "          P4       0.75      0.72      0.74      1053\n",
            "\n",
            "    accuracy                           0.77      8413\n",
            "   macro avg       0.70      0.67      0.68      8413\n",
            "weighted avg       0.75      0.77      0.76      8413\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **HYperparamter tuning**"
      ],
      "metadata": {
        "id": "l7G_eOqvO8J8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    \"colsample_bytree\": [0.3, 0.5],\n",
        "    \"learning_rate\": [0.05, 0.1],\n",
        "    \"max_depth\": [3, 5],\n",
        "    \"alpha\": [1, 10],\n",
        "    \"n_estimators\": [50, 100],\n",
        "}\n",
        "\n",
        "best_test_acc = 0\n",
        "best_params = None\n",
        "\n",
        "results = []\n",
        "\n",
        "index = 0\n",
        "for colsample in param_grid[\"colsample_bytree\"]:\n",
        "    for lr in param_grid[\"learning_rate\"]:\n",
        "        for md in param_grid[\"max_depth\"]:\n",
        "            for alpha in param_grid[\"alpha\"]:\n",
        "                for n_est in param_grid[\"n_estimators\"]:\n",
        "                    model = xgb.XGBClassifier(\n",
        "                        objective=\"multi:softmax\",\n",
        "                        num_class=len(label_encoder.classes_),\n",
        "                        colsample_bytree=colsample,\n",
        "                        learning_rate=lr,\n",
        "                        max_depth=md,\n",
        "                        alpha=alpha,\n",
        "                        n_estimators=n_est,\n",
        "                        random_state=42\n",
        "                    )\n",
        "\n",
        "                    model.fit(X_train_xgb, y_train_xgb)\n",
        "\n",
        "                    y_train_pred = model.predict(X_train_xgb)\n",
        "                    y_test_pred = model.predict(X_test_xgb)\n",
        "\n",
        "                    train_acc = accuracy_score(y_train_xgb, y_train_pred)\n",
        "                    test_acc = accuracy_score(y_test_xgb, y_test_pred)\n",
        "\n",
        "                    results.append(\n",
        "                        (\n",
        "                            index,\n",
        "                            train_acc,\n",
        "                            test_acc,\n",
        "                            colsample,\n",
        "                            lr,\n",
        "                            md,\n",
        "                            alpha,\n",
        "                            n_est,\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "                    if test_acc > best_test_acc:\n",
        "                        best_test_acc = test_acc\n",
        "                        best_params = (colsample, lr, md, alpha, n_est)\n",
        "\n",
        "                    print(f\"Combo {index}: train={train_acc:.3f}  test={test_acc:.3f}\")\n",
        "                    index += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpRnige4Oyie",
        "outputId": "8135123b-fab4-49a2-bf12-84dff1904721"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combo 0: train=0.706  test=0.706\n",
            "Combo 1: train=0.747  test=0.743\n",
            "Combo 2: train=0.704  test=0.703\n",
            "Combo 3: train=0.746  test=0.742\n",
            "Combo 4: train=0.737  test=0.731\n",
            "Combo 5: train=0.772  test=0.760\n",
            "Combo 6: train=0.730  test=0.724\n",
            "Combo 7: train=0.766  test=0.756\n",
            "Combo 8: train=0.747  test=0.744\n",
            "Combo 9: train=0.771  test=0.765\n",
            "Combo 10: train=0.745  test=0.742\n",
            "Combo 11: train=0.769  test=0.763\n",
            "Combo 12: train=0.772  test=0.761\n",
            "Combo 13: train=0.796  test=0.774\n",
            "Combo 14: train=0.766  test=0.758\n",
            "Combo 15: train=0.786  test=0.771\n",
            "Combo 16: train=0.736  test=0.730\n",
            "Combo 17: train=0.759  test=0.750\n",
            "Combo 18: train=0.735  test=0.729\n",
            "Combo 19: train=0.757  test=0.748\n",
            "Combo 20: train=0.765  test=0.755\n",
            "Combo 21: train=0.785  test=0.770\n",
            "Combo 22: train=0.761  test=0.751\n",
            "Combo 23: train=0.780  test=0.768\n",
            "Combo 24: train=0.757  test=0.750\n",
            "Combo 25: train=0.776  test=0.767\n",
            "Combo 26: train=0.757  test=0.751\n",
            "Combo 27: train=0.774  test=0.765\n",
            "Combo 28: train=0.785  test=0.769\n",
            "Combo 29: train=0.803  test=0.773\n",
            "Combo 30: train=0.780  test=0.766\n",
            "Combo 31: train=0.793  test=0.775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nBest XGBoost test accuracy:\", best_test_acc)\n",
        "print(\"Best params (colsample_bytree, learning_rate, max_depth, alpha, n_estimators):\")\n",
        "print(best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNamNsYhPDwK",
        "outputId": "463b44f6-e3c4-4fe4-b945-f22da9085c25"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best XGBoost test accuracy: 0.7745156305717342\n",
            "Best params (colsample_bytree, learning_rate, max_depth, alpha, n_estimators):\n",
            "(0.5, 0.1, 5, 10, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jplCogIyTZnz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}